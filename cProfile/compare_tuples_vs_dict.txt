(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ python -m cProfile -s time main_index.py -b cacm
0 / 8976
1000 / 8976
2000 / 8976
3000 / 8976
4000 / 8976
5000 / 8976
6000 / 8976
7000 / 8976
8000 / 8976
1000 / 3203
2000 / 3203
3000 / 3203
0 / 3203
1000 / 3203
2000 / 3203
3000 / 3203
Document IDs saved
0 / 8976
1000 / 8976
2000 / 8976
3000 / 8976
4000 / 8976
5000 / 8976
6000 / 8976
7000 / 8976
8000 / 8976
Term IDs saved
0 / 8976
500 / 8976
1000 / 8976
1500 / 8976
2000 / 8976
2500 / 8976
3000 / 8976
3500 / 8976
4000 / 8976
4500 / 8976
5000 / 8976
5500 / 8976
6000 / 8976
6500 / 8976
7000 / 8976
7500 / 8976
8000 / 8976
8500 / 8976
Index saved
         2892372 function calls (2892366 primitive calls) in 1.916 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   110296    0.273    0.000    0.821    0.000 linguistic_treatment.py:127(tokenize_by_line)
   110296    0.258    0.000    0.258    0.000 {method 'split' of '_sre.SRE_Pattern' objects}
        1    0.172    0.172    1.266    1.266 index.py:174(build_index)
     3204    0.141    0.000    0.193    0.000 collections.py:528(update)
     3204    0.130    0.000    0.332    0.000 index.py:141(fill_index)
   586580    0.117    0.000    0.117    0.000 {method 'startswith' of 'str' objects}
    91556    0.100    0.000    0.162    0.000 linguistic_treatment.py:134(line_to_analyse)
   216170    0.081    0.000    0.081    0.000 {method 'readline' of 'file' objects}
   110296    0.078    0.000    0.078    0.000 re.py:230(_compile)
        1    0.073    0.073    0.526    0.526 linguistic_treatment.py:102(tokenize)
   110296    0.072    0.000    0.408    0.000 re.py:168(split)
   110296    0.057    0.000    0.057    0.000 {method 'lower' of 'str' objects}
   691250    0.050    0.000    0.050    0.000 {method 'isdigit' of 'str' objects}
   104271    0.046    0.000    0.071    0.000 index.py:165(starts_with_id)
        1    0.044    0.044    0.050    0.050 index.py:66(save_index)
   306512    0.035    0.000    0.035    0.000 {method 'get' of 'dict' objects}
   104880    0.034    0.000    0.055    0.000 index.py:171(starts_with_any_marker)
   110296    0.032    0.000    0.089    0.000 string.py:222(lower)
        1    0.015    0.015    0.015    0.015 linguistic_treatment.py:53(remove_duplication)
        1    0.014    0.014    1.916    1.916 main_index.py:1(<module>)
    35217    0.012    0.000    0.019    0.000 linguistic_treatment.py:140(line_to_read)
     3204    0.009    0.000    0.202    0.000 collections.py:458(__init__)
        1    0.008    0.008    0.012    0.012 index.py:56(save_term_ids)
     3204    0.008    0.000    0.014    0.000 abc.py:128(__instancecheck__)
        1    0.008    0.008    0.010    0.010 index.py:27(build_term_ids)
    33333    0.008    0.000    0.008    0.000 index.py:154(print_position)
    21157    0.008    0.000    0.008    0.000 {method 'write' of 'file' objects}
        1    0.005    0.005    0.005    0.005 {sorted}
        1    0.005    0.005    0.026    0.026 linguistic_treatment.py:31(build_vocabulary_list)
     6409    0.004    0.000    0.004    0.000 _weakrefset.py:70(__contains__)
        1    0.003    0.003    0.006    0.006 index.py:48(save_doc_ids)
     3213    0.003    0.000    0.016    0.000 {isinstance}
     3812    0.002    0.000    0.002    0.000 {method 'replace' of 'str' objects}
        6    0.002    0.000    0.002    0.000 {open}
        1    0.002    0.002    0.003    0.003 collections.py:11(<module>)
     3204    0.001    0.000    0.002    0.000 index.py:168(starts_with_title)
        1    0.001    0.001    0.005    0.005 index.py:1(<module>)
     3206    0.001    0.000    0.001    0.000 {getattr}
        1    0.001    0.001    0.001    0.001 heapq.py:31(<module>)
6436/6435    0.001    0.000    0.001    0.000 {len}
        1    0.001    0.001    0.001    0.001 linguistic_treatment.py:1(<module>)
        1    0.000    0.000    0.000    0.000 {method 'readlines' of 'file' objects}
        1    0.000    0.000    0.001    0.001 linguistic_treatment.py:56(get_common_words)
      429    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {range}
        1    0.000    0.000    0.552    0.552 linguistic_treatment.py:11(__init__)
        1    0.000    0.000    0.069    0.069 index.py:77(save_all)
      2/1    0.000    0.000    0.000    0.000 abc.py:148(__subclasscheck__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:395(_parse)
        1    0.000    0.000    0.000    0.000 collections.py:38(OrderedDict)
        1    0.000    0.000    1.828    1.828 index.py:161(__init__)
        1    0.000    0.000    1.276    1.276 index.py:12(__init__)
      3/2    0.000    0.000    0.000    0.000 sre_parse.py:151(getwidth)
        4    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
      2/1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:36(__init__)
        1    0.000    0.000    0.000    0.000 keyword.py:11(<module>)
        1    0.000    0.000    0.000    0.000 sre_parse.py:706(parse)
        1    0.000    0.000    1.897    1.897 main_index.py:6(build_index)
        1    0.000    0.000    0.000    0.000 sre_compile.py:567(compile)
        1    0.000    0.000    0.000    0.000 sre_compile.py:433(_compile_info)
      3/1    0.000    0.000    0.000    0.000 {issubclass}
        1    0.000    0.000    0.000    0.000 sre_compile.py:256(_optimize_charset)
        5    0.000    0.000    0.000    0.000 sre_parse.py:193(__next)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
        1    0.000    0.000    0.000    0.000 collections.py:407(Counter)
        3    0.000    0.000    0.000    0.000 index.py:45(get_path)
       19    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 index.py:209(CS276Index)
        1    0.000    0.000    0.000    0.000 settings.py:2(<module>)
        1    0.000    0.000    0.000    0.000 sre_compile.py:228(_compile_charset)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
        1    0.000    0.000    0.000    0.000 index.py:10(Index)
        1    0.000    0.000    0.552    0.552 linguistic_treatment.py:99(__init__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:149(append)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:9(LinguisticTreatment)
        1    0.000    0.000    0.000    0.000 sre_parse.py:317(_parse_sub)
        6    0.000    0.000    0.000    0.000 sre_parse.py:141(__getitem__)
        1    0.000    0.000    0.000    0.000 index.py:159(CACMIndex)
        4    0.000    0.000    0.000    0.000 sre_parse.py:137(__len__)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:97(CACMLinguisticTreatment)
        1    0.000    0.000    0.000    0.000 sre_compile.py:552(_code)
        1    0.000    0.000    0.000    0.000 sre_compile.py:428(_simple)
        1    0.000    0.000    0.000    0.000 {_sre.compile}
        2    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:83(add)
        1    0.000    0.000    0.000    0.000 sre_parse.py:189(__init__)
        2    0.000    0.000    0.000    0.000 sre_compile.py:546(isstring)
        2    0.000    0.000    0.000    0.000 _abcoll.py:98(__subclasshook__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:268(_escape)
        1    0.000    0.000    0.000    0.000 sre_parse.py:67(__init__)
        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
        2    0.000    0.000    0.000    0.000 sre_parse.py:92(__init__)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:22(get_vocabulary_size)
        1    0.000    0.000    0.000    0.000 sre_parse.py:145(__setitem__)
        4    0.000    0.000    0.000    0.000 sre_parse.py:212(get)
        4    0.000    0.000    0.000    0.000 {min}
        2    0.000    0.000    0.000    0.000 sre_parse.py:206(match)
        2    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:144(CS276LinguisticTreatment)
        2    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        4    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}


(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ python -m cProfile -s time main_index.py -g cacm
Doc IDs length : 3204
Term IDs length : 8975
Index length : 8975
         1282472 function calls (1282469 primitive calls) in 0.732 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    91556    0.101    0.000    0.163    0.000 linguistic_treatment.py:134(line_to_analyse)
    25793    0.087    0.000    0.087    0.000 {method 'split' of '_sre.SRE_Pattern' objects}
        1    0.076    0.076    0.527    0.527 linguistic_treatment.py:102(tokenize)
   395382    0.074    0.000    0.074    0.000 {method 'startswith' of 'str' objects}
    25793    0.073    0.000    0.234    0.000 linguistic_treatment.py:127(tokenize_by_line)
        1    0.061    0.061    0.265    0.265 index.py:124(get_index)
   129245    0.046    0.000    0.046    0.000 {method 'readline' of 'file' objects}
    98264    0.031    0.000    0.053    0.000 index.py:136(<genexpr>)
    98264    0.030    0.000    0.030    0.000 {method 'split' of 'str' objects}
    25793    0.018    0.000    0.018    0.000 {method 'lower' of 'str' objects}
        1    0.018    0.018    0.027    0.027 index.py:108(get_term_ids)
    25793    0.017    0.000    0.017    0.000 re.py:230(_compile)
    25793    0.016    0.000    0.120    0.000 re.py:168(split)
   218953    0.015    0.000    0.015    0.000 {method 'isdigit' of 'str' objects}
    35217    0.012    0.000    0.020    0.000 linguistic_treatment.py:140(line_to_read)
        1    0.012    0.012    0.012    0.012 linguistic_treatment.py:53(remove_duplication)
        1    0.008    0.008    0.858    0.858 main_index.py:1(<module>)
    25793    0.007    0.000    0.025    0.000 string.py:222(lower)
        1    0.006    0.006    0.010    0.010 index.py:88(get_doc_ids)
    21154    0.006    0.000    0.006    0.000 {method 'replace' of 'str' objects}
    21154    0.005    0.000    0.005    0.000 {method 'index' of 'str' objects}
    17950    0.004    0.000    0.004    0.000 {method 'rindex' of 'str' objects}
        1    0.003    0.003    0.003    0.003 {sorted}
        1    0.003    0.003    0.018    0.018 linguistic_treatment.py:31(build_vocabulary_list)
        1    0.001    0.001    0.003    0.003 collections.py:11(<module>)
        1    0.001    0.001    0.001    0.001 heapq.py:31(<module>)
        1    0.001    0.001    0.004    0.004 index.py:1(<module>)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:1(<module>)
        5    0.000    0.000    0.000    0.000 {open}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:56(get_common_words)
        1    0.000    0.000    0.545    0.545 linguistic_treatment.py:11(__init__)
      429    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'readlines' of 'file' objects}
        1    0.000    0.000    0.000    0.000 sre_parse.py:395(_parse)
        1    0.000    0.000    0.000    0.000 collections.py:38(OrderedDict)
        1    0.000    0.000    0.847    0.847 main_index.py:6(build_index)
      2/1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)
      3/2    0.000    0.000    0.000    0.000 sre_parse.py:151(getwidth)
        1    0.000    0.000    0.545    0.545 linguistic_treatment.py:99(__init__)
        1    0.000    0.000    0.302    0.302 index.py:12(__init__)
        1    0.000    0.000    0.000    0.000 sre_compile.py:433(_compile_info)
        1    0.000    0.000    0.000    0.000 sre_compile.py:567(compile)
        1    0.000    0.000    0.000    0.000 {_sre.compile}
        1    0.000    0.000    0.000    0.000 sre_compile.py:256(_optimize_charset)
        1    0.000    0.000    0.000    0.000 sre_parse.py:189(__init__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:706(parse)
        1    0.000    0.000    0.000    0.000 collections.py:407(Counter)
        1    0.000    0.000    0.847    0.847 index.py:161(__init__)
        1    0.000    0.000    0.000    0.000 index.py:10(Index)
        9    0.000    0.000    0.000    0.000 {isinstance}
        1    0.000    0.000    0.000    0.000 index.py:209(CS276Index)
        1    0.000    0.000    0.000    0.000 sre_compile.py:228(_compile_charset)
        1    0.000    0.000    0.000    0.000 keyword.py:11(<module>)
        3    0.000    0.000    0.000    0.000 index.py:45(get_path)
        5    0.000    0.000    0.000    0.000 sre_parse.py:193(__next)
        1    0.000    0.000    0.000    0.000 sre_compile.py:552(_code)
    28/27    0.000    0.000    0.000    0.000 {len}
        1    0.000    0.000    0.000    0.000 sre_parse.py:317(_parse_sub)
        1    0.000    0.000    0.000    0.000 sre_compile.py:428(_simple)
        6    0.000    0.000    0.000    0.000 sre_parse.py:141(__getitem__)
        4    0.000    0.000    0.000    0.000 sre_parse.py:212(get)
        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
        1    0.000    0.000    0.000    0.000 index.py:159(CACMIndex)
        4    0.000    0.000    0.000    0.000 sre_parse.py:137(__len__)
        1    0.000    0.000    0.000    0.000 settings.py:2(<module>)
        2    0.000    0.000    0.000    0.000 sre_compile.py:546(isstring)
        4    0.000    0.000    0.000    0.000 {min}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:9(LinguisticTreatment)
        1    0.000    0.000    0.000    0.000 sre_parse.py:149(append)
        2    0.000    0.000    0.000    0.000 sre_parse.py:92(__init__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:268(_escape)
       19    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:144(CS276LinguisticTreatment)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:97(CACMLinguisticTreatment)
        1    0.000    0.000    0.000    0.000 sre_parse.py:67(__init__)
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 sre_parse.py:145(__setitem__)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        2    0.000    0.000    0.000    0.000 sre_parse.py:206(match)


(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ python -m cProfile -s time main_index.py -b cs276
0 / 8976
1000 / 8976
2000 / 8976
3000 / 8976
4000 / 8976
5000 / 8976
6000 / 8976
7000 / 8976
8000 / 8976
CS276 Index building
####                                      10 %
Length of tmp index : 6833
########                                  20 %
Length of tmp index : 6944
############                              30 %
Length of tmp index : 6831
################                          40 %
Length of tmp index : 7271
####################                      50 %
Length of tmp index : 7059
########################                  60 %
Length of tmp index : 7080
############################              70 %
Length of tmp index : 7095
################################          80 %
Length of tmp index : 6930
####################################      90 %
Length of tmp index : 7100
########################################  100 %
Length of tmp index : 6810
0 / 3203
1000 / 3203
2000 / 3203
3000 / 3203
4000 / 3203
5000 / 3203
6000 / 3203
7000 / 3203
8000 / 3203
9000 / 3203
10000 / 3203
11000 / 3203
12000 / 3203
13000 / 3203
14000 / 3203
15000 / 3203
16000 / 3203
17000 / 3203
18000 / 3203
19000 / 3203
20000 / 3203
21000 / 3203
22000 / 3203
23000 / 3203
24000 / 3203
25000 / 3203
26000 / 3203
27000 / 3203
28000 / 3203
29000 / 3203
30000 / 3203
31000 / 3203
32000 / 3203
33000 / 3203
34000 / 3203
35000 / 3203
36000 / 3203
37000 / 3203
38000 / 3203
39000 / 3203
40000 / 3203
41000 / 3203
42000 / 3203
43000 / 3203
44000 / 3203
45000 / 3203
46000 / 3203
47000 / 3203
48000 / 3203
49000 / 3203
50000 / 3203
51000 / 3203
52000 / 3203
53000 / 3203
54000 / 3203
55000 / 3203
56000 / 3203
57000 / 3203
58000 / 3203
59000 / 3203
60000 / 3203
61000 / 3203
62000 / 3203
63000 / 3203
64000 / 3203
65000 / 3203
66000 / 3203
67000 / 3203
68000 / 3203
69000 / 3203
70000 / 3203
71000 / 3203
72000 / 3203
73000 / 3203
74000 / 3203
75000 / 3203
76000 / 3203
77000 / 3203
78000 / 3203
79000 / 3203
80000 / 3203
81000 / 3203
82000 / 3203
83000 / 3203
84000 / 3203
85000 / 3203
86000 / 3203
87000 / 3203
88000 / 3203
89000 / 3203
90000 / 3203
91000 / 3203
92000 / 3203
93000 / 3203
94000 / 3203
95000 / 3203
96000 / 3203
97000 / 3203
98000 / 3203
Document IDs saved
0 / 8976
1000 / 8976
2000 / 8976
3000 / 8976
4000 / 8976
5000 / 8976
6000 / 8976
7000 / 8976
8000 / 8976
Term IDs saved
         71774552 function calls (71774546 primitive calls) in 71.980 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   437159   16.314    0.000   16.314    0.000 {method 'readline' of 'file' objects}
    98998    9.705    0.000   13.178    0.000 collections.py:528(update)
    98998    8.287    0.000   21.943    0.000 index.py:141(fill_index)
 21297658    8.010    0.000    8.010    0.000 {method 'split' of 'str' objects}
 21198660    6.304    0.000   11.682    0.000 index.py:306(<genexpr>)
       19    5.382    0.283    5.935    0.312 index.py:259(save_tmp_index)
       18    5.167    0.287   49.505    2.750 index.py:294(get_tmp_index)
 25498341    2.815    0.000    2.815    0.000 {method 'get' of 'dict' objects}
       10    1.923    0.192   44.095    4.410 index.py:237(build_block_index)
    99039    1.747    0.000    1.747    0.000 {open}
       12    1.382    0.115    1.382    0.115 {posix.listdir}
    61788    0.954    0.000    0.954    0.000 {method 'update' of 'dict' objects}
   247201    0.610    0.000    0.610    0.000 {method 'write' of 'file' objects}
        1    0.492    0.492   55.545   55.545 index.py:271(merge_indexes)
    98998    0.458    0.000   13.656    0.000 collections.py:458(__init__)
        1    0.377    0.377  101.418  101.418 index.py:225(build_index)
    98998    0.321    0.000    0.545    0.000 abc.py:128(__instancecheck__)
   197997    0.182    0.000    0.182    0.000 _weakrefset.py:70(__contains__)
    98998    0.165    0.000    0.251    0.000 index.py:252(create_new_doc_id)
   262084    0.158    0.000    0.158    0.000 {method 'replace' of 'str' objects}
   197996    0.128    0.000    0.128    0.000 index.py:216(get_file_path)
   505285    0.119    0.000    0.119    0.000 {method 'startswith' of 'str' objects}
        1    0.113    0.113    0.192    0.192 index.py:48(save_doc_ids)
    91556    0.106    0.000    0.172    0.000 linguistic_treatment.py:134(line_to_analyse)
    99007    0.104    0.000    0.649    0.000 {isinstance}
    25793    0.098    0.000    0.098    0.000 {method 'split' of '_sre.SRE_Pattern' objects}
        1    0.082    0.082    0.574    0.574 linguistic_treatment.py:102(tokenize)
    25793    0.080    0.000    0.258    0.000 linguistic_treatment.py:127(tokenize_by_line)
   262084    0.064    0.000    0.064    0.000 {method 'index' of 'str' objects}
    99000    0.043    0.000    0.043    0.000 {getattr}
        9    0.037    0.004    0.991    0.110 index.py:311(merge_index_dictionaries)
198045/198044    0.028    0.000    0.028    0.000 {len}
   116948    0.028    0.000    0.028    0.000 index.py:154(print_position)
        1    0.021    0.021  101.448  101.448 index.py:12(__init__)
    25793    0.020    0.000    0.020    0.000 re.py:230(_compile)
    25793    0.020    0.000    0.020    0.000 {method 'lower' of 'str' objects}
    25793    0.018    0.000    0.136    0.000 re.py:168(split)
        1    0.017    0.017    0.025    0.025 index.py:56(save_term_ids)
       18    0.016    0.001    0.016    0.001 {posix.remove}
   218953    0.016    0.000    0.016    0.000 {method 'isdigit' of 'str' objects}
        1    0.015    0.015  102.280  102.280 main_index.py:1(<module>)
        1    0.014    0.014    0.014    0.014 linguistic_treatment.py:53(remove_duplication)
    35217    0.013    0.000    0.022    0.000 linguistic_treatment.py:140(line_to_read)
        1    0.008    0.008    0.010    0.010 index.py:27(build_term_ids)
    25793    0.007    0.000    0.027    0.000 string.py:222(lower)
        1    0.005    0.005    0.005    0.005 {sorted}
        1    0.004    0.004    0.023    0.023 linguistic_treatment.py:31(build_vocabulary_list)
       30    0.002    0.000    0.002    0.000 {posix.getcwd}
        5    0.001    0.000    0.001    0.000 index.py:290(pairwise)
        1    0.001    0.001    0.002    0.002 collections.py:11(<module>)
        1    0.001    0.001    0.001    0.001 heapq.py:31(<module>)
        1    0.001    0.001    0.003    0.003 index.py:1(<module>)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:1(<module>)
        1    0.000    0.000    0.000    0.000 {range}
        1    0.000    0.000    0.596    0.596 linguistic_treatment.py:11(__init__)
       54    0.000    0.000    0.000    0.000 index.py:222(get_tmp_path)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:56(get_common_words)
        1    0.000    0.000    0.218    0.218 index.py:77(save_all)
      429    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
       19    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}
       10    0.000    0.000    0.001    0.000 index.py:219(get_folder_path)
        1    0.000    0.000    0.000    0.000 {method 'readlines' of 'file' objects}
      2/1    0.000    0.000    0.000    0.000 abc.py:148(__subclasscheck__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:395(_parse)
        1    0.000    0.000  102.045  102.045 index.py:211(__init__)
        3    0.000    0.000    0.000    0.000 index.py:45(get_path)
      2/1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)
        1    0.000    0.000    0.000    0.000 collections.py:38(OrderedDict)
        1    0.000    0.000  102.263  102.263 main_index.py:6(build_index)
      3/2    0.000    0.000    0.000    0.000 sre_parse.py:151(getwidth)
        4    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
        1    0.000    0.000    0.000    0.000 sre_compile.py:567(compile)
       28    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 sre_compile.py:256(_optimize_charset)
        1    0.000    0.000    0.000    0.000 sre_parse.py:706(parse)
        1    0.000    0.000    0.000    0.000 sre_compile.py:433(_compile_info)
        1    0.000    0.000    0.000    0.000 keyword.py:11(<module>)
        5    0.000    0.000    0.000    0.000 {iter}
        2    0.000    0.000    0.000    0.000 _weakrefset.py:36(__init__)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:317(_parse_sub)
        1    0.000    0.000    0.000    0.000 collections.py:407(Counter)
        1    0.000    0.000    0.000    0.000 index.py:209(CS276Index)
        5    0.000    0.000    0.000    0.000 sre_parse.py:193(__next)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
        6    0.000    0.000    0.000    0.000 sre_parse.py:141(__getitem__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:268(_escape)
        1    0.000    0.000    0.596    0.596 linguistic_treatment.py:99(__init__)
        1    0.000    0.000    0.000    0.000 settings.py:2(<module>)
        1    0.000    0.000    0.000    0.000 sre_compile.py:228(_compile_charset)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:9(LinguisticTreatment)
        2    0.000    0.000    0.000    0.000 sre_compile.py:546(isstring)
        1    0.000    0.000    0.000    0.000 index.py:10(Index)
        2    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}
        1    0.000    0.000    0.000    0.000 sre_compile.py:552(_code)
        2    0.000    0.000    0.000    0.000 sre_parse.py:92(__init__)
        1    0.000    0.000    0.000    0.000 sre_compile.py:428(_simple)
        1    0.000    0.000    0.000    0.000 {_sre.compile}
        2    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:83(add)
      3/1    0.000    0.000    0.000    0.000 {issubclass}
        1    0.000    0.000    0.000    0.000 index.py:159(CACMIndex)
        1    0.000    0.000    0.000    0.000 sre_parse.py:149(append)
        1    0.000    0.000    0.000    0.000 sre_parse.py:67(__init__)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:97(CACMLinguisticTreatment)
        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:22(get_vocabulary_size)
        4    0.000    0.000    0.000    0.000 sre_parse.py:212(get)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
        4    0.000    0.000    0.000    0.000 {min}
        1    0.000    0.000    0.000    0.000 sre_parse.py:189(__init__)
        4    0.000    0.000    0.000    0.000 sre_parse.py:137(__len__)
        2    0.000    0.000    0.000    0.000 sre_parse.py:206(match)
        2    0.000    0.000    0.000    0.000 _abcoll.py:98(__subclasshook__)
        4    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 sre_parse.py:145(__setitem__)
        2    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:144(CS276LinguisticTreatment)


(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ python -m cProfile -s time main_index.py -g cs276
Doc IDs length : 98998
Term IDs length : 8975
Index length : 8165
         13791968 function calls (13791965 primitive calls) in 6.173 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
  6163854    1.736    0.000    1.736    0.000 {method 'split' of 'str' objects}
  6163854    1.719    0.000    3.185    0.000 index.py:136(<genexpr>)
        1    1.371    1.371   13.533   13.533 index.py:124(get_index)
   224229    0.310    0.000    0.310    0.000 {method 'readline' of 'file' objects}
        1    0.203    0.203    0.324    0.324 index.py:88(get_doc_ids)
        1    0.171    0.171   14.621   14.621 main_index.py:1(<module>)
    91556    0.101    0.000    0.165    0.000 linguistic_treatment.py:134(line_to_analyse)
   490366    0.096    0.000    0.096    0.000 {method 'startswith' of 'str' objects}
    25793    0.089    0.000    0.089    0.000 {method 'split' of '_sre.SRE_Pattern' objects}
    25793    0.078    0.000    0.242    0.000 linguistic_treatment.py:127(tokenize_by_line)
        1    0.076    0.076    0.540    0.540 linguistic_treatment.py:102(tokenize)
   115328    0.062    0.000    0.062    0.000 {method 'replace' of 'str' objects}
   115328    0.024    0.000    0.024    0.000 {method 'index' of 'str' objects}
    25793    0.019    0.000    0.019    0.000 {method 'lower' of 'str' objects}
        1    0.018    0.018    0.027    0.027 index.py:108(get_term_ids)
    25793    0.017    0.000    0.017    0.000 re.py:230(_compile)
    25793    0.016    0.000    0.123    0.000 re.py:168(split)
   218953    0.015    0.000    0.015    0.000 {method 'isdigit' of 'str' objects}
        1    0.013    0.013    0.013    0.013 linguistic_treatment.py:53(remove_duplication)
    35217    0.012    0.000    0.020    0.000 linguistic_treatment.py:140(line_to_read)
    25793    0.007    0.000    0.026    0.000 string.py:222(lower)
        1    0.004    0.004    0.004    0.004 {sorted}
    17950    0.004    0.000    0.004    0.000 {method 'rindex' of 'str' objects}
        1    0.003    0.003    0.022    0.022 linguistic_treatment.py:31(build_vocabulary_list)
        1    0.001    0.001    0.002    0.002 collections.py:11(<module>)
        1    0.001    0.001    0.005    0.005 index.py:1(<module>)
        1    0.001    0.001    0.001    0.001 {method 'readlines' of 'file' objects}
        1    0.001    0.001    0.001    0.001 heapq.py:31(<module>)
        1    0.001    0.001    0.001    0.001 linguistic_treatment.py:1(<module>)
        1    0.000    0.000    0.002    0.002 linguistic_treatment.py:56(get_common_words)
        1    0.000    0.000    0.562    0.562 linguistic_treatment.py:11(__init__)
      429    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        5    0.000    0.000    0.000    0.000 {open}
        1    0.000    0.000   14.446   14.446 main_index.py:6(build_index)
        1    0.000    0.000   13.883   13.883 index.py:12(__init__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:395(_parse)
        1    0.000    0.000    0.000    0.000 collections.py:38(OrderedDict)
        1    0.000    0.000   14.446   14.446 index.py:211(__init__)
      3/2    0.000    0.000    0.000    0.000 sre_parse.py:151(getwidth)
      2/1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)
        1    0.000    0.000    0.000    0.000 sre_parse.py:706(parse)
        1    0.000    0.000    0.000    0.000 keyword.py:11(<module>)
        1    0.000    0.000    0.000    0.000 sre_compile.py:567(compile)
        3    0.000    0.000    0.000    0.000 index.py:45(get_path)
        1    0.000    0.000    0.000    0.000 sre_compile.py:256(_optimize_charset)
        5    0.000    0.000    0.000    0.000 sre_parse.py:193(__next)
        1    0.000    0.000    0.000    0.000 collections.py:407(Counter)
        1    0.000    0.000    0.000    0.000 sre_compile.py:433(_compile_info)
        1    0.000    0.000    0.562    0.562 linguistic_treatment.py:99(__init__)
        6    0.000    0.000    0.000    0.000 sre_parse.py:141(__getitem__)
        1    0.000    0.000    0.000    0.000 index.py:209(CS276Index)
        1    0.000    0.000    0.000    0.000 sre_compile.py:552(_code)
        1    0.000    0.000    0.000    0.000 sre_compile.py:228(_compile_charset)
        9    0.000    0.000    0.000    0.000 {isinstance}
        1    0.000    0.000    0.000    0.000 settings.py:2(<module>)
       19    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 index.py:10(Index)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:9(LinguisticTreatment)
        1    0.000    0.000    0.000    0.000 sre_parse.py:268(_escape)
        1    0.000    0.000    0.000    0.000 sre_parse.py:317(_parse_sub)
        1    0.000    0.000    0.000    0.000 {_sre.compile}
        1    0.000    0.000    0.000    0.000 index.py:159(CACMIndex)
        4    0.000    0.000    0.000    0.000 sre_parse.py:137(__len__)
        2    0.000    0.000    0.000    0.000 sre_compile.py:546(isstring)
        4    0.000    0.000    0.000    0.000 sre_parse.py:212(get)
        1    0.000    0.000    0.000    0.000 sre_compile.py:428(_simple)
        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
    28/27    0.000    0.000    0.000    0.000 {len}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:97(CACMLinguisticTreatment)
        4    0.000    0.000    0.000    0.000 {min}
        1    0.000    0.000    0.000    0.000 sre_parse.py:149(append)
        2    0.000    0.000    0.000    0.000 sre_parse.py:92(__init__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:189(__init__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:67(__init__)
        2    0.000    0.000    0.000    0.000 sre_parse.py:206(match)
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:144(CS276LinguisticTreatment)
        1    0.000    0.000    0.000    0.000 sre_parse.py:145(__setitem__)


(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ git status
On branch master
Your branch is ahead of 'origin/master' by 1 commit.
  (use "git push" to publish your local commits)
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)

    modified:   index.py
    modified:   indexes/cacm/index.txt
    modified:   indexes/cs276/index.txt
    modified:   search.py

no changes added to commit (use "git add" and/or "git commit -a")
(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ git stash
Saved working directory and index state WIP on master: 514440c Search and order results by frequencies
HEAD is now at 514440c Search and order results by frequencies
(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ python -m cProfile -s time main_index.py -b cacm
0 / 8976
1000 / 8976
2000 / 8976
3000 / 8976
4000 / 8976
5000 / 8976
6000 / 8976
7000 / 8976
8000 / 8976
1000 / 3203
2000 / 3203
3000 / 3203
0 / 3203
1000 / 3203
2000 / 3203
3000 / 3203
Document IDs saved
0 / 8976
1000 / 8976
2000 / 8976
3000 / 8976
4000 / 8976
5000 / 8976
6000 / 8976
7000 / 8976
8000 / 8976
Term IDs saved
0 / 8976
500 / 8976
1000 / 8976
1500 / 8976
2000 / 8976
2500 / 8976
3000 / 8976
3500 / 8976
4000 / 8976
4500 / 8976
5000 / 8976
5500 / 8976
6000 / 8976
6500 / 8976
7000 / 8976
7500 / 8976
8000 / 8976
8500 / 8976
Index saved
         2990636 function calls (2990630 primitive calls) in 2.002 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   110296    0.277    0.000    0.277    0.000 {method 'split' of '_sre.SRE_Pattern' objects}
   110296    0.262    0.000    0.826    0.000 linguistic_treatment.py:127(tokenize_by_line)
        1    0.173    0.173    1.275    1.275 index.py:178(build_index)
     3204    0.130    0.000    0.182    0.000 collections.py:528(update)
     3204    0.124    0.000    0.328    0.000 index.py:145(fill_index)
   586580    0.118    0.000    0.118    0.000 {method 'startswith' of 'str' objects}
    91556    0.099    0.000    0.161    0.000 linguistic_treatment.py:134(line_to_analyse)
     8975    0.091    0.000    0.091    0.000 {map}
   216170    0.087    0.000    0.087    0.000 {method 'readline' of 'file' objects}
   110296    0.077    0.000    0.077    0.000 re.py:230(_compile)
        1    0.076    0.076    0.524    0.524 linguistic_treatment.py:102(tokenize)
   110296    0.071    0.000    0.425    0.000 re.py:168(split)
   110296    0.057    0.000    0.057    0.000 {method 'lower' of 'str' objects}
   691250    0.050    0.000    0.050    0.000 {method 'isdigit' of 'str' objects}
   104271    0.044    0.000    0.070    0.000 index.py:169(starts_with_id)
   306512    0.035    0.000    0.035    0.000 {method 'get' of 'dict' objects}
   104880    0.033    0.000    0.055    0.000 index.py:175(starts_with_any_marker)
   110296    0.031    0.000    0.088    0.000 string.py:222(lower)
        1    0.025    0.025    2.002    2.002 main_index.py:1(<module>)
        1    0.021    0.021    0.126    0.126 index.py:66(save_index)
        1    0.012    0.012    0.012    0.012 linguistic_treatment.py:53(remove_duplication)
    21157    0.012    0.000    0.012    0.000 {method 'write' of 'file' objects}
    80333    0.012    0.000    0.012    0.000 {method 'append' of 'list' objects}
    35217    0.011    0.000    0.019    0.000 linguistic_treatment.py:140(line_to_read)
     3204    0.010    0.000    0.192    0.000 collections.py:458(__init__)
        1    0.009    0.009    0.013    0.013 index.py:56(save_term_ids)
     3204    0.008    0.000    0.014    0.000 abc.py:128(__instancecheck__)
    33333    0.008    0.000    0.008    0.000 index.py:158(print_position)
        1    0.006    0.006    0.008    0.008 index.py:27(build_term_ids)
        1    0.004    0.004    0.021    0.021 linguistic_treatment.py:31(build_vocabulary_list)
     6409    0.004    0.000    0.004    0.000 _weakrefset.py:70(__contains__)
        1    0.004    0.004    0.004    0.004 {sorted}
     8975    0.003    0.000    0.003    0.000 {method 'join' of 'str' objects}
     3213    0.003    0.000    0.017    0.000 {isinstance}
        1    0.003    0.003    0.004    0.004 index.py:48(save_doc_ids)
     3812    0.002    0.000    0.002    0.000 {method 'replace' of 'str' objects}
     3204    0.002    0.000    0.003    0.000 index.py:172(starts_with_title)
        1    0.001    0.001    0.002    0.002 collections.py:11(<module>)
        1    0.001    0.001    0.002    0.002 linguistic_treatment.py:1(<module>)
        1    0.001    0.001    0.005    0.005 index.py:1(<module>)
     3206    0.001    0.000    0.001    0.000 {getattr}
6436/6435    0.001    0.000    0.001    0.000 {len}
        1    0.001    0.001    0.001    0.001 heapq.py:31(<module>)
        6    0.000    0.000    0.000    0.000 {open}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:97(CACMLinguisticTreatment)
        1    0.000    0.000    0.000    0.000 {range}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:56(get_common_words)
      429    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        1    0.000    0.000    0.546    0.546 linguistic_treatment.py:11(__init__)
        1    0.000    0.000    0.143    0.143 index.py:77(save_all)
        1    0.000    0.000    0.000    0.000 {method 'readlines' of 'file' objects}
      2/1    0.000    0.000    0.000    0.000 abc.py:148(__subclasscheck__)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:9(LinguisticTreatment)
        4    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:395(_parse)
        1    0.000    0.000    1.829    1.829 index.py:165(__init__)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
        1    0.000    0.000    0.000    0.000 keyword.py:11(<module>)
        1    0.000    0.000    0.000    0.000 collections.py:38(OrderedDict)
      2/1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)
        1    0.000    0.000    1.283    1.283 index.py:12(__init__)
      3/2    0.000    0.000    0.000    0.000 sre_parse.py:151(getwidth)
        1    0.000    0.000    0.000    0.000 index.py:213(CS276Index)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:36(__init__)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
      3/1    0.000    0.000    0.000    0.000 {issubclass}
        1    0.000    0.000    0.000    0.000 settings.py:2(<module>)
        1    0.000    0.000    0.000    0.000 sre_parse.py:706(parse)
        1    0.000    0.000    0.000    0.000 sre_compile.py:433(_compile_info)
        1    0.000    0.000    0.000    0.000 sre_compile.py:256(_optimize_charset)
        1    0.000    0.000    1.972    1.972 main_index.py:6(build_index)
        1    0.000    0.000    0.000    0.000 sre_compile.py:567(compile)
        5    0.000    0.000    0.000    0.000 sre_parse.py:193(__next)
        1    0.000    0.000    0.000    0.000 collections.py:407(Counter)
        3    0.000    0.000    0.000    0.000 index.py:45(get_path)
        1    0.000    0.000    0.000    0.000 index.py:10(Index)
        1    0.000    0.000    0.546    0.546 linguistic_treatment.py:99(__init__)
        4    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.000    0.000 sre_compile.py:552(_code)
        1    0.000    0.000    0.000    0.000 sre_compile.py:228(_compile_charset)
        1    0.000    0.000    0.000    0.000 sre_compile.py:428(_simple)
        1    0.000    0.000    0.000    0.000 sre_parse.py:317(_parse_sub)
        6    0.000    0.000    0.000    0.000 sre_parse.py:141(__getitem__)
        4    0.000    0.000    0.000    0.000 sre_parse.py:137(__len__)
        1    0.000    0.000    0.000    0.000 index.py:163(CACMIndex)
        2    0.000    0.000    0.000    0.000 sre_parse.py:92(__init__)
        1    0.000    0.000    0.000    0.000 {_sre.compile}
        4    0.000    0.000    0.000    0.000 sre_parse.py:212(get)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
        4    0.000    0.000    0.000    0.000 {min}
        2    0.000    0.000    0.000    0.000 _weakrefset.py:83(add)
        2    0.000    0.000    0.000    0.000 sre_compile.py:546(isstring)
        2    0.000    0.000    0.000    0.000 sre_parse.py:206(match)
        2    0.000    0.000    0.000    0.000 _abcoll.py:98(__subclasshook__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:268(_escape)
        1    0.000    0.000    0.000    0.000 sre_parse.py:149(append)
        1    0.000    0.000    0.000    0.000 sre_parse.py:67(__init__)
        2    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}
        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:22(get_vocabulary_size)
        1    0.000    0.000    0.000    0.000 sre_parse.py:189(__init__)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:144(CS276LinguisticTreatment)
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 sre_parse.py:145(__setitem__)
        2    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}


(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ python -m cProfile -s time main_index.py -g cacm
Doc IDs length : 3204
Term IDs length : 8975
Index length : 8975
         1362786 function calls (1362783 primitive calls) in 0.890 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.216    0.216    0.306    0.306 index.py:124(get_index)
    91556    0.099    0.000    0.162    0.000 linguistic_treatment.py:134(line_to_analyse)
    25793    0.086    0.000    0.086    0.000 {method 'split' of '_sre.SRE_Pattern' objects}
   395382    0.075    0.000    0.075    0.000 {method 'startswith' of 'str' objects}
    25793    0.073    0.000    0.231    0.000 linguistic_treatment.py:127(tokenize_by_line)
        1    0.073    0.073    0.520    0.520 linguistic_treatment.py:102(tokenize)
   129245    0.047    0.000    0.047    0.000 {method 'readline' of 'file' objects}
   181782    0.040    0.000    0.040    0.000 {method 'replace' of 'str' objects}
    98264    0.030    0.000    0.030    0.000 {method 'split' of 'str' objects}
    25793    0.019    0.000    0.019    0.000 {method 'lower' of 'str' objects}
        1    0.016    0.016    0.024    0.024 index.py:108(get_term_ids)
    25793    0.016    0.000    0.016    0.000 re.py:230(_compile)
    25793    0.016    0.000    0.118    0.000 re.py:168(split)
   218953    0.015    0.000    0.015    0.000 {method 'isdigit' of 'str' objects}
    35217    0.012    0.000    0.019    0.000 linguistic_treatment.py:140(line_to_read)
        1    0.011    0.011    0.011    0.011 linguistic_treatment.py:53(remove_duplication)
        1    0.009    0.009    0.890    0.890 main_index.py:1(<module>)
    35900    0.009    0.000    0.009    0.000 {method 'rindex' of 'str' objects}
    25793    0.007    0.000    0.025    0.000 string.py:222(lower)
        1    0.006    0.006    0.010    0.010 index.py:88(get_doc_ids)
        1    0.004    0.004    0.004    0.004 {sorted}
     8975    0.004    0.000    0.004    0.000 {range}
        1    0.003    0.003    0.018    0.018 linguistic_treatment.py:31(build_vocabulary_list)
        1    0.001    0.001    0.002    0.002 collections.py:11(<module>)
        1    0.001    0.001    0.003    0.003 index.py:1(<module>)
9003/9002    0.001    0.000    0.001    0.000 {len}
        1    0.001    0.001    0.001    0.001 heapq.py:31(<module>)
     3204    0.001    0.000    0.001    0.000 {method 'index' of 'str' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:1(<module>)
        5    0.000    0.000    0.000    0.000 {open}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:56(get_common_words)
        1    0.000    0.000    0.538    0.538 linguistic_treatment.py:11(__init__)
      429    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        1    0.000    0.000    0.878    0.878 main_index.py:6(build_index)
        1    0.000    0.000    0.000    0.000 {method 'readlines' of 'file' objects}
        1    0.000    0.000    0.000    0.000 collections.py:38(OrderedDict)
        1    0.000    0.000    0.000    0.000 sre_parse.py:395(_parse)
        1    0.000    0.000    0.000    0.000 collections.py:407(Counter)
        1    0.000    0.000    0.339    0.339 index.py:12(__init__)
        1    0.000    0.000    0.000    0.000 index.py:213(CS276Index)
        1    0.000    0.000    0.878    0.878 index.py:165(__init__)
        1    0.000    0.000    0.000    0.000 keyword.py:11(<module>)
        1    0.000    0.000    0.000    0.000 index.py:10(Index)
      2/1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)
      3/2    0.000    0.000    0.000    0.000 sre_parse.py:151(getwidth)
        1    0.000    0.000    0.000    0.000 sre_parse.py:706(parse)
        1    0.000    0.000    0.000    0.000 sre_compile.py:256(_optimize_charset)
        6    0.000    0.000    0.000    0.000 sre_parse.py:141(__getitem__)
        3    0.000    0.000    0.000    0.000 index.py:45(get_path)
        1    0.000    0.000    0.000    0.000 sre_compile.py:567(compile)
        1    0.000    0.000    0.538    0.538 linguistic_treatment.py:99(__init__)
        1    0.000    0.000    0.000    0.000 sre_compile.py:433(_compile_info)
        5    0.000    0.000    0.000    0.000 sre_parse.py:193(__next)
        1    0.000    0.000    0.000    0.000 sre_compile.py:228(_compile_charset)
        1    0.000    0.000    0.000    0.000 sre_parse.py:317(_parse_sub)
        1    0.000    0.000    0.000    0.000 settings.py:2(<module>)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:9(LinguisticTreatment)
        1    0.000    0.000    0.000    0.000 sre_parse.py:268(_escape)
       19    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 sre_compile.py:552(_code)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:97(CACMLinguisticTreatment)
        1    0.000    0.000    0.000    0.000 sre_parse.py:149(append)
        9    0.000    0.000    0.000    0.000 {isinstance}
        1    0.000    0.000    0.000    0.000 sre_parse.py:189(__init__)
        2    0.000    0.000    0.000    0.000 sre_compile.py:546(isstring)
        4    0.000    0.000    0.000    0.000 sre_parse.py:212(get)
        1    0.000    0.000    0.000    0.000 index.py:163(CACMIndex)
        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
        4    0.000    0.000    0.000    0.000 {min}
        2    0.000    0.000    0.000    0.000 sre_parse.py:92(__init__)
        4    0.000    0.000    0.000    0.000 sre_parse.py:137(__len__)
        1    0.000    0.000    0.000    0.000 {_sre.compile}
        1    0.000    0.000    0.000    0.000 sre_parse.py:67(__init__)
        2    0.000    0.000    0.000    0.000 sre_parse.py:206(match)
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 sre_parse.py:145(__setitem__)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 sre_compile.py:428(_simple)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:144(CS276LinguisticTreatment)


(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ python -m cProfile -s time main_index.py -b cs276
0 / 8976
1000 / 8976
2000 / 8976
3000 / 8976
4000 / 8976
5000 / 8976
6000 / 8976
7000 / 8976
8000 / 8976
CS276 Index building
####                                      10 %
Length of tmp index : 6833
########                                  20 %
Length of tmp index : 6944
############                              30 %
Length of tmp index : 6831
################                          40 %
Length of tmp index : 7271
####################                      50 %
Length of tmp index : 7059
########################                  60 %
Length of tmp index : 7080
############################              70 %
Length of tmp index : 7095
################################          80 %
Length of tmp index : 6930
####################################      90 %
Length of tmp index : 7100
########################################  100 %
Length of tmp index : 6810
0 / 3203
1000 / 3203
2000 / 3203
3000 / 3203
4000 / 3203
5000 / 3203
6000 / 3203
7000 / 3203
8000 / 3203
9000 / 3203
10000 / 3203
11000 / 3203
12000 / 3203
13000 / 3203
14000 / 3203
15000 / 3203
16000 / 3203
17000 / 3203
18000 / 3203
19000 / 3203
20000 / 3203
21000 / 3203
22000 / 3203
23000 / 3203
24000 / 3203
25000 / 3203
26000 / 3203
27000 / 3203
28000 / 3203
29000 / 3203
30000 / 3203
31000 / 3203
32000 / 3203
33000 / 3203
34000 / 3203
35000 / 3203
36000 / 3203
37000 / 3203
38000 / 3203
39000 / 3203
40000 / 3203
41000 / 3203
42000 / 3203
43000 / 3203
44000 / 3203
45000 / 3203
46000 / 3203
47000 / 3203
48000 / 3203
49000 / 3203
50000 / 3203
51000 / 3203
52000 / 3203
53000 / 3203
54000 / 3203
55000 / 3203
56000 / 3203
57000 / 3203
58000 / 3203
59000 / 3203
60000 / 3203
61000 / 3203
62000 / 3203
63000 / 3203
64000 / 3203
65000 / 3203
66000 / 3203
67000 / 3203
68000 / 3203
69000 / 3203
70000 / 3203
71000 / 3203
72000 / 3203
73000 / 3203
74000 / 3203
75000 / 3203
76000 / 3203
77000 / 3203
78000 / 3203
79000 / 3203
80000 / 3203
81000 / 3203
82000 / 3203
83000 / 3203
84000 / 3203
85000 / 3203
86000 / 3203
87000 / 3203
88000 / 3203
89000 / 3203
90000 / 3203
91000 / 3203
92000 / 3203
93000 / 3203
94000 / 3203
95000 / 3203
96000 / 3203
97000 / 3203
98000 / 3203
Document IDs saved
0 / 8976
1000 / 8976
2000 / 8976
3000 / 8976
4000 / 8976
5000 / 8976
6000 / 8976
7000 / 8976
8000 / 8976
Term IDs saved
         36265550 function calls (36265544 primitive calls) in 54.590 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   437159   15.938    0.000   15.938    0.000 {method 'readline' of 'file' objects}
    98998    9.737    0.000   13.217    0.000 collections.py:528(update)
    98998    8.377    0.000   22.848    0.000 index.py:145(fill_index)
   139207    4.842    0.000    4.842    0.000 {map}
 25498341    2.812    0.000    2.812    0.000 {method 'get' of 'dict' objects}
   361082    2.210    0.000    2.210    0.000 {method 'split' of 'str' objects}
       10    1.937    0.194   44.625    4.463 index.py:241(build_block_index)
    99039    1.328    0.000    1.328    0.000 {open}
       12    1.066    0.089    1.066    0.089 {posix.listdir}
       18    0.974    0.054    2.480    0.138 index.py:298(get_tmp_index)
        1    0.959    0.959   53.704   53.704 index.py:229(build_index)
  6085764    0.710    0.000    0.710    0.000 {method 'append' of 'list' objects}
    98998    0.523    0.000   13.761    0.000 collections.py:458(__init__)
       19    0.332    0.017    5.509    0.290 index.py:263(save_tmp_index)
    98998    0.327    0.000    0.550    0.000 abc.py:128(__instancecheck__)
   262084    0.308    0.000    0.308    0.000 {method 'replace' of 'str' objects}
   247201    0.287    0.000    0.287    0.000 {method 'write' of 'file' objects}
   197997    0.179    0.000    0.179    0.000 _weakrefset.py:70(__contains__)
    98998    0.167    0.000    0.253    0.000 index.py:256(create_new_doc_id)
   262084    0.161    0.000    0.161    0.000 {method 'rindex' of 'str' objects}
   197996    0.128    0.000    0.128    0.000 index.py:220(get_file_path)
        1    0.114    0.114    0.192    0.192 index.py:48(save_doc_ids)
    99007    0.108    0.000    0.658    0.000 {isinstance}
   139207    0.107    0.000    0.107    0.000 {method 'join' of 'str' objects}
   505285    0.104    0.000    0.104    0.000 {method 'startswith' of 'str' objects}
    91556    0.100    0.000    0.162    0.000 linguistic_treatment.py:134(line_to_analyse)
        1    0.093    0.093   53.805   53.805 index.py:12(__init__)
    25793    0.087    0.000    0.087    0.000 {method 'split' of '_sre.SRE_Pattern' objects}
    25793    0.072    0.000    0.231    0.000 linguistic_treatment.py:127(tokenize_by_line)
        1    0.071    0.071    0.518    0.518 linguistic_treatment.py:102(tokenize)
        9    0.057    0.006    0.088    0.010 index.py:319(merge_index_dictionaries)
    99000    0.044    0.000    0.044    0.000 {getattr}
329087/329086    0.041    0.000    0.041    0.000 {len}
   131043    0.037    0.000    0.037    0.000 {range}
    61789    0.036    0.000    0.036    0.000 {sorted}
        1    0.029    0.029    2.845    2.845 index.py:275(merge_indexes)
   116948    0.028    0.000    0.028    0.000 index.py:158(print_position)
        1    0.023    0.023    0.034    0.034 index.py:56(save_term_ids)
        1    0.019    0.019   54.590   54.590 main_index.py:1(<module>)
    25793    0.019    0.000    0.019    0.000 {method 'lower' of 'str' objects}
    25793    0.016    0.000    0.016    0.000 re.py:230(_compile)
    25793    0.016    0.000    0.119    0.000 re.py:168(split)
   218953    0.014    0.000    0.014    0.000 {method 'isdigit' of 'str' objects}
        1    0.012    0.012    0.012    0.012 linguistic_treatment.py:53(remove_duplication)
    35217    0.011    0.000    0.019    0.000 linguistic_treatment.py:140(line_to_read)
       18    0.009    0.000    0.009    0.000 {posix.remove}
    25793    0.007    0.000    0.026    0.000 string.py:222(lower)
        1    0.006    0.006    0.008    0.008 index.py:27(build_term_ids)
        1    0.003    0.003    0.020    0.020 linguistic_treatment.py:31(build_vocabulary_list)
       30    0.002    0.000    0.002    0.000 {posix.getcwd}
        1    0.001    0.001    0.001    0.001 collections.py:11(<module>)
        1    0.001    0.001    0.001    0.001 heapq.py:31(<module>)
        1    0.001    0.001    0.002    0.002 index.py:1(<module>)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:1(<module>)
        1    0.000    0.000    0.226    0.226 index.py:77(save_all)
       54    0.000    0.000    0.000    0.000 index.py:226(get_tmp_path)
      429    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:56(get_common_words)
        1    0.000    0.000    0.538    0.538 linguistic_treatment.py:11(__init__)
       10    0.000    0.000    0.001    0.000 index.py:223(get_folder_path)
        5    0.000    0.000    0.000    0.000 index.py:294(pairwise)
        1    0.000    0.000    0.000    0.000 {method 'readlines' of 'file' objects}
        1    0.000    0.000   54.569   54.569 main_index.py:6(build_index)
      2/1    0.000    0.000    0.000    0.000 abc.py:148(__subclasscheck__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:395(_parse)
       19    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}
        1    0.000    0.000   54.343   54.343 index.py:215(__init__)
        3    0.000    0.000    0.000    0.000 index.py:45(get_path)
      2/1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)
        4    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)
      3/2    0.000    0.000    0.000    0.000 sre_parse.py:151(getwidth)
        1    0.000    0.000    0.000    0.000 collections.py:38(OrderedDict)
        1    0.000    0.000    0.000    0.000 sre_parse.py:706(parse)
        1    0.000    0.000    0.000    0.000 sre_compile.py:433(_compile_info)
        1    0.000    0.000    0.000    0.000 sre_compile.py:256(_optimize_charset)
        5    0.000    0.000    0.000    0.000 sre_parse.py:193(__next)
        5    0.000    0.000    0.000    0.000 {iter}
        1    0.000    0.000    0.000    0.000 keyword.py:11(<module>)
        1    0.000    0.000    0.000    0.000 collections.py:407(Counter)
        1    0.000    0.000    0.000    0.000 sre_compile.py:567(compile)
      3/1    0.000    0.000    0.000    0.000 {issubclass}
        1    0.000    0.000    0.000    0.000 sre_compile.py:228(_compile_charset)
        1    0.000    0.000    0.000    0.000 index.py:213(CS276Index)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:36(__init__)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)
        1    0.000    0.000    0.538    0.538 linguistic_treatment.py:99(__init__)
        1    0.000    0.000    0.000    0.000 sre_compile.py:552(_code)
        6    0.000    0.000    0.000    0.000 sre_parse.py:141(__getitem__)
        4    0.000    0.000    0.000    0.000 sre_parse.py:212(get)
        1    0.000    0.000    0.000    0.000 index.py:10(Index)
        1    0.000    0.000    0.000    0.000 sre_parse.py:268(_escape)
        1    0.000    0.000    0.000    0.000 settings.py:2(<module>)
        2    0.000    0.000    0.000    0.000 sre_parse.py:92(__init__)
        1    0.000    0.000    0.000    0.000 {_sre.compile}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:9(LinguisticTreatment)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:83(add)
        1    0.000    0.000    0.000    0.000 sre_parse.py:317(_parse_sub)
        2    0.000    0.000    0.000    0.000 sre_compile.py:546(isstring)
        2    0.000    0.000    0.000    0.000 _abcoll.py:98(__subclasshook__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:149(append)
        1    0.000    0.000    0.000    0.000 sre_parse.py:67(__init__)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:97(CACMLinguisticTreatment)
        1    0.000    0.000    0.000    0.000 index.py:163(CACMIndex)
        2    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}
        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:22(get_vocabulary_size)
        1    0.000    0.000    0.000    0.000 sre_compile.py:428(_simple)
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        2    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)
        2    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)
        4    0.000    0.000    0.000    0.000 {min}
        1    0.000    0.000    0.000    0.000 sre_parse.py:189(__init__)
        2    0.000    0.000    0.000    0.000 sre_parse.py:206(match)
        2    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}
        1    0.000    0.000    0.000    0.000 sre_parse.py:145(__setitem__)
        4    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        4    0.000    0.000    0.000    0.000 sre_parse.py:137(__len__)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:144(CS276LinguisticTreatment)


(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ python -m cProfile -s time main_index.py -g cs276
Doc IDs length : 98998
Term IDs length : 8975
Index length : 8165
         1496920 function calls (1496917 primitive calls) in 0.959 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.202    0.202    0.321    0.321 index.py:88(get_doc_ids)
    91556    0.099    0.000    0.160    0.000 linguistic_treatment.py:134(line_to_analyse)
   224229    0.091    0.000    0.091    0.000 {method 'readline' of 'file' objects}
   490366    0.091    0.000    0.091    0.000 {method 'startswith' of 'str' objects}
    25793    0.086    0.000    0.086    0.000 {method 'split' of '_sre.SRE_Pattern' objects}
        1    0.072    0.072    0.516    0.516 linguistic_treatment.py:102(tokenize)
    25793    0.072    0.000    0.230    0.000 linguistic_treatment.py:127(tokenize_by_line)
        1    0.045    0.045    0.068    0.068 index.py:124(get_index)
   115328    0.035    0.000    0.035    0.000 {method 'replace' of 'str' objects}
    98998    0.020    0.000    0.020    0.000 {method 'index' of 'str' objects}
    25793    0.018    0.000    0.018    0.000 {method 'lower' of 'str' objects}
        1    0.016    0.016    0.023    0.023 index.py:108(get_term_ids)
    25793    0.016    0.000    0.118    0.000 re.py:168(split)
    25793    0.016    0.000    0.016    0.000 re.py:230(_compile)
   218953    0.014    0.000    0.014    0.000 {method 'isdigit' of 'str' objects}
        1    0.012    0.012    0.012    0.012 linguistic_treatment.py:53(remove_duplication)
    35217    0.011    0.000    0.019    0.000 linguistic_treatment.py:140(line_to_read)
        1    0.009    0.009    0.959    0.959 main_index.py:1(<module>)
    34280    0.007    0.000    0.007    0.000 {method 'rindex' of 'str' objects}
    25793    0.007    0.000    0.025    0.000 string.py:222(lower)
    16330    0.006    0.000    0.006    0.000 {method 'split' of 'str' objects}
        1    0.004    0.004    0.004    0.004 {sorted}
        1    0.003    0.003    0.018    0.018 linguistic_treatment.py:31(build_vocabulary_list)
     8165    0.002    0.000    0.002    0.000 {range}
        1    0.001    0.001    0.002    0.002 collections.py:11(<module>)
        1    0.001    0.001    0.001    0.001 heapq.py:31(<module>)
        1    0.001    0.001    0.004    0.004 index.py:1(<module>)
8193/8192    0.001    0.000    0.001    0.000 {len}
        1    0.001    0.001    0.001    0.001 linguistic_treatment.py:1(<module>)
        5    0.000    0.000    0.000    0.000 {open}
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:56(get_common_words)
        1    0.000    0.000    0.534    0.534 linguistic_treatment.py:11(__init__)
      429    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'readlines' of 'file' objects}
        1    0.000    0.000    0.947    0.947 main_index.py:6(build_index)
        1    0.000    0.000    0.000    0.000 sre_parse.py:395(_parse)
        1    0.000    0.000    0.412    0.412 index.py:12(__init__)
      2/1    0.000    0.000    0.000    0.000 sre_compile.py:64(_compile)
        1    0.000    0.000    0.000    0.000 collections.py:38(OrderedDict)
        1    0.000    0.000    0.947    0.947 index.py:215(__init__)
      3/2    0.000    0.000    0.000    0.000 sre_parse.py:151(getwidth)
        1    0.000    0.000    0.000    0.000 sre_compile.py:567(compile)
        1    0.000    0.000    0.000    0.000 keyword.py:11(<module>)
        1    0.000    0.000    0.000    0.000 sre_parse.py:706(parse)
        1    0.000    0.000    0.000    0.000 sre_compile.py:256(_optimize_charset)
        1    0.000    0.000    0.000    0.000 collections.py:407(Counter)
        1    0.000    0.000    0.000    0.000 sre_compile.py:433(_compile_info)
        6    0.000    0.000    0.000    0.000 sre_parse.py:141(__getitem__)
        3    0.000    0.000    0.000    0.000 index.py:45(get_path)
        1    0.000    0.000    0.000    0.000 sre_compile.py:228(_compile_charset)
        1    0.000    0.000    0.000    0.000 index.py:213(CS276Index)
        1    0.000    0.000    0.000    0.000 index.py:10(Index)
        5    0.000    0.000    0.000    0.000 sre_parse.py:193(__next)
        1    0.000    0.000    0.534    0.534 linguistic_treatment.py:99(__init__)
        1    0.000    0.000    0.000    0.000 settings.py:2(<module>)
        1    0.000    0.000    0.000    0.000 sre_compile.py:552(_code)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:9(LinguisticTreatment)
        1    0.000    0.000    0.000    0.000 sre_parse.py:149(append)
        1    0.000    0.000    0.000    0.000 sre_parse.py:268(_escape)
        1    0.000    0.000    0.000    0.000 sre_parse.py:317(_parse_sub)
        4    0.000    0.000    0.000    0.000 sre_parse.py:212(get)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:97(CACMLinguisticTreatment)
        2    0.000    0.000    0.000    0.000 sre_parse.py:92(__init__)
        9    0.000    0.000    0.000    0.000 {isinstance}
        1    0.000    0.000    0.000    0.000 {_sre.compile}
        1    0.000    0.000    0.000    0.000 sre_parse.py:189(__init__)
        2    0.000    0.000    0.000    0.000 sre_compile.py:546(isstring)
        1    0.000    0.000    0.000    0.000 sre_compile.py:428(_simple)
       19    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 index.py:163(CACMIndex)
        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}
        4    0.000    0.000    0.000    0.000 {min}
        4    0.000    0.000    0.000    0.000 sre_parse.py:137(__len__)
        1    0.000    0.000    0.000    0.000 sre_parse.py:67(__init__)
        1    0.000    0.000    0.000    0.000 linguistic_treatment.py:144(CS276LinguisticTreatment)
        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
        2    0.000    0.000    0.000    0.000 sre_parse.py:206(match)
        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 sre_parse.py:145(__setitem__)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}


(ENV) MacBook-Pro-de-Melanie:information-retrieval melanie$ 
